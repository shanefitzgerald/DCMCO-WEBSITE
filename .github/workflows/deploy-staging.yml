name: Deploy to Staging

on:
  push:
    branches:
      - main
  workflow_dispatch:

permissions:
  contents: read
  id-token: write

env:
  NODE_VERSION: '20'
  TERRAFORM_VERSION: '1.6.0'

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: staging

    steps:
      # ============================================
      # 1. Checkout and Setup
      # ============================================
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 9

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'pnpm'

      # Cache CDKTF CLI global installation
      - name: Cache CDKTF CLI
        uses: actions/cache@v4
        with:
          path: ~/.local/share/pnpm/global
          key: ${{ runner.os }}-cdktf-cli-${{ hashFiles('infrastructure/package.json') }}
          restore-keys: |
            ${{ runner.os }}-cdktf-cli-

      # Cache infrastructure node_modules separately
      - name: Cache infrastructure dependencies
        uses: actions/cache@v4
        with:
          path: infrastructure/node_modules
          key: ${{ runner.os }}-infra-${{ hashFiles('infrastructure/pnpm-lock.yaml') }}
          restore-keys: |
            ${{ runner.os }}-infra-

      # Cache CDKTF provider bindings (significant time saver)
      - name: Cache CDKTF provider bindings
        uses: actions/cache@v4
        with:
          path: infrastructure/imports
          key: ${{ runner.os }}-cdktf-imports-${{ hashFiles('infrastructure/cdktf.json', 'infrastructure/package.json') }}
          restore-keys: |
            ${{ runner.os }}-cdktf-imports-

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}
          terraform_wrapper: false

      # ============================================
      # 2. Authenticate to GCP
      # ============================================
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCP_SERVICE_ACCOUNT }}

      - name: Setup Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      # ============================================
      # 3. Configure npm authentication BEFORE any pnpm commands
      # ============================================
      - name: Configure npm authentication for Artifact Registry
        run: |
          # Generate auth token using gcloud
          TOKEN=$(gcloud auth print-access-token)

          # Create .npmrc with scope configuration and auth token
          cat > .npmrc << EOF
          @dcmco:registry=https://australia-southeast1-npm.pkg.dev/dcmco-prod-2026/npm-packages/
          //australia-southeast1-npm.pkg.dev/dcmco-prod-2026/npm-packages/:always-auth=true
          //australia-southeast1-npm.pkg.dev/dcmco-prod-2026/npm-packages/:_authToken=${TOKEN}
          EOF

          # Verify .npmrc configuration
          echo "=== .npmrc contents AFTER CREATION ==="
          cat .npmrc
          echo "=== END .npmrc ==="

      # ============================================
      # 4. Deploy Infrastructure with CDKTF
      # ============================================
      - name: Install CDKTF CLI
        run: |
          if command -v cdktf &> /dev/null; then
            echo "âœ“ CDKTF CLI already available (from cache)"
            cdktf --version
          else
            echo "Installing CDKTF CLI..."
            pnpm install -g cdktf-cli@^0.20.0
          fi

      - name: Install infrastructure dependencies
        working-directory: ./infrastructure
        run: |
          if [ -d "node_modules" ] && [ -n "$(ls -A node_modules 2>/dev/null)" ]; then
            echo "âœ“ Infrastructure dependencies restored from cache"
            echo "Running pnpm install --prefer-offline for verification..."
            pnpm install --prefer-offline --frozen-lockfile
          else
            echo "Installing infrastructure dependencies..."
            pnpm install --frozen-lockfile
          fi

      - name: Generate CDKTF provider bindings
        working-directory: ./infrastructure
        run: |
          if [ -d "imports" ] && [ -n "$(ls -A imports 2>/dev/null)" ]; then
            echo "âœ“ CDKTF provider bindings restored from cache"
          else
            echo "Generating CDKTF provider bindings..."
            pnpm run get
          fi

      - name: Create infrastructure .env file
        working-directory: ./infrastructure
        run: |
          cat > .env << EOF
          GCP_PROJECT_ID=${{ secrets.GCP_PROJECT_ID }}
          GCP_REGION=${{ secrets.GCP_REGION }}
          GCS_BUCKET_NAME=${{ secrets.GCS_BUCKET_NAME_STAGING }}
          GCS_BUCKET_LOCATION=${{ secrets.GCS_BUCKET_LOCATION }}
          ENVIRONMENT=staging
          EOF

      - name: CDKTF Synth
        working-directory: ./infrastructure
        run: pnpm run synth

      - name: Import existing bucket if needed
        working-directory: ./infrastructure
        run: |
          # Check if bucket exists
          if gcloud storage buckets describe "gs://${{ secrets.GCS_BUCKET_NAME_STAGING }}" &>/dev/null; then
            echo "Bucket exists, checking if it's in state..."

            # Initialize Terraform backend
            cd cdktf.out/stacks/dcmco-website-storage
            terraform init

            # Check if bucket is already in state
            if ! terraform state list | grep -q "google_storage_bucket.website-bucket"; then
              echo "Importing existing bucket into Terraform state..."
              terraform import google_storage_bucket.website-bucket "${{ secrets.GCS_BUCKET_NAME_STAGING }}"
              echo "âœ“ Bucket imported successfully"
            else
              echo "âœ“ Bucket already in state"
            fi

            cd ../../..
          else
            echo "Bucket doesn't exist yet, will be created by deploy"
          fi

      - name: CDKTF Deploy
        working-directory: ./infrastructure
        run: cdktf deploy --auto-approve

      # ============================================
      # 5. Build Next.js Site
      # ============================================
      # Cache Next.js build output for faster rebuilds
      - name: Cache Next.js build
        uses: actions/cache@v4
        with:
          path: |
            .next/cache
            out/.next/cache
          key: ${{ runner.os }}-nextjs-${{ hashFiles('pnpm-lock.yaml') }}-${{ hashFiles('**.[jt]s', '**.[jt]sx', '!**/node_modules/**') }}
          restore-keys: |
            ${{ runner.os }}-nextjs-${{ hashFiles('pnpm-lock.yaml') }}-
            ${{ runner.os }}-nextjs-

      - name: Install website dependencies
        run: |
          # Note: pnpm cache is already handled by setup-node cache: 'pnpm'
          # This uses the pnpm-lock.yaml from the repository
          echo "Installing website dependencies..."
          pnpm install --frozen-lockfile --prefer-offline

      - name: Build Next.js site
        run: pnpm run build
        env:
          # Add any build-time environment variables here
          NEXT_PUBLIC_ENV: staging

      # ============================================
      # 6. Deploy to GCS
      # ============================================
      - name: Upload to GCS
        run: |
          echo "Uploading static site to gs://${{ secrets.GCS_BUCKET_NAME_STAGING }}/"
          # -m: parallel uploads, -r: recursive, -d: delete removed files
          # rsync only uploads changed files (incremental upload)
          gsutil -m rsync -r -d out/ gs://${{ secrets.GCS_BUCKET_NAME_STAGING }}/

      - name: Set Cache-Control headers
        env:
          BUCKET: gs://${{ secrets.GCS_BUCKET_NAME_STAGING }}
        run: |
          echo "Setting cache-control headers for different file types..."
          echo "Note: More specific patterns are applied last to override general patterns"
          echo ""

          # 1. HTML files - Always revalidate (0 seconds)
          echo "â†’ HTML files: max-age=0, must-revalidate"
          gsutil -m setmeta -h "Cache-Control:public, max-age=0, must-revalidate" \
            "${BUCKET}/**/*.html" 2>/dev/null || echo "  No HTML files found"

          # 2. CSS and JS (general) - Cache for 1 hour (3600 seconds)
          echo "â†’ CSS/JS files (general): max-age=3600 (1 hour)"
          gsutil -m setmeta -h "Cache-Control:public, max-age=3600" \
            "${BUCKET}/**/*.css" "${BUCKET}/**/*.js" 2>/dev/null || echo "  No CSS/JS files found"

          # 3. JSON files - Cache for 1 hour
          echo "â†’ JSON files: max-age=3600 (1 hour)"
          gsutil -m setmeta -h "Cache-Control:public, max-age=3600" \
            "${BUCKET}/**/*.json" 2>/dev/null || echo "  No JSON files found"

          # 4. Images - Cache for 30 days (2592000 seconds)
          echo "â†’ Images: max-age=2592000 (30 days)"
          gsutil -m setmeta -h "Cache-Control:public, max-age=2592000" \
            "${BUCKET}/**/*.png" "${BUCKET}/**/*.jpg" "${BUCKET}/**/*.jpeg" \
            "${BUCKET}/**/*.svg" "${BUCKET}/**/*.webp" "${BUCKET}/**/*.gif" \
            "${BUCKET}/**/*.ico" 2>/dev/null || echo "  No image files found"

          # 5. Fonts - Cache for 1 year (immutable)
          echo "â†’ Fonts: max-age=31536000, immutable"
          gsutil -m setmeta -h "Cache-Control:public, max-age=31536000, immutable" \
            "${BUCKET}/**/*.woff" "${BUCKET}/**/*.woff2" "${BUCKET}/**/*.ttf" \
            "${BUCKET}/**/*.otf" "${BUCKET}/**/*.eot" 2>/dev/null || echo "  No font files found"

          # 6. Next.js hashed static assets - Cache forever (1 year) - MUST BE LAST
          echo "â†’ Next.js hashed assets: max-age=31536000, immutable (overriding general CSS/JS)"
          gsutil -m setmeta -h "Cache-Control:public, max-age=31536000, immutable" \
            "${BUCKET}/_next/static/**" 2>/dev/null || echo "  No Next.js static assets found"

          echo "âœ“ Cache headers set successfully"

      # ============================================
      # 7. Verification
      # ============================================
      - name: Verify deployment
        run: |
          echo "âœ… Deployment completed successfully!"
          echo "ðŸŒ Website URL: https://storage.googleapis.com/${{ secrets.GCS_BUCKET_NAME_STAGING }}/index.html"

          # Test if index.html is accessible
          curl -f -s -o /dev/null https://storage.googleapis.com/${{ secrets.GCS_BUCKET_NAME_STAGING }}/index.html || \
            (echo "âŒ Website is not accessible" && exit 1)

          echo "âœ… Website is accessible and serving content"

      # ============================================
      # 8. CDN Cache Invalidation (if configured)
      # ============================================
      - name: Invalidate CDN cache
        if: ${{ vars.CDN_URL_MAP != '' }}
        continue-on-error: true
        run: |
          echo "ðŸ”„ Invalidating CDN cache..."
          echo "CDN URL Map: ${{ vars.CDN_URL_MAP }}"

          # Invalidate all paths in the CDN
          gcloud compute url-maps invalidate-cdn-cache "${{ vars.CDN_URL_MAP }}" \
            --path "/*" \
            --async \
            --quiet || {
              echo "âš ï¸  CDN cache invalidation failed, but continuing deployment"
              echo "This is not critical - cache will expire naturally"
              exit 0
            }

          echo "âœ“ CDN cache invalidation started (running asynchronously)"
          echo "Note: Cache invalidation may take a few minutes to complete"

      - name: Skip CDN invalidation
        if: ${{ vars.CDN_URL_MAP == '' }}
        run: |
          echo "â„¹ï¸  No CDN configured (CDN_URL_MAP not set)"
          echo "Skipping cache invalidation step"

      # ============================================
      # 9. Summary
      # ============================================
      - name: Deployment Summary
        if: always()
        env:
          BUCKET_NAME: ${{ secrets.GCS_BUCKET_NAME_STAGING }}
          PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
          BUCKET_REGION: ${{ secrets.GCS_BUCKET_LOCATION }}
        run: |
          echo "## Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Environment:** Staging" >> $GITHUB_STEP_SUMMARY
          echo "- **GCP Project:** ${PROJECT_ID}" >> $GITHUB_STEP_SUMMARY
          echo "- **Bucket:** ${BUCKET_NAME}" >> $GITHUB_STEP_SUMMARY
          echo "- **Region:** ${BUCKET_REGION}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ”— Links" >> $GITHUB_STEP_SUMMARY
          echo "- [Website](https://storage.googleapis.com/${BUCKET_NAME}/index.html)" >> $GITHUB_STEP_SUMMARY
          echo "- [GCS Bucket](https://console.cloud.google.com/storage/browser/${BUCKET_NAME})" >> $GITHUB_STEP_SUMMARY
